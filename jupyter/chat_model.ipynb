{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c52e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 优先用ChatTongyi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7026fdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_community.chat_models import ChatTongyi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7d2715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"build_effective_agents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68352ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.getenv(\"OPENAI_BASE_URL\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc95324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai兼容模式qwen,不要用这种方式\n",
    "llm = ChatOpenAI(\n",
    "    model=\"qwen-max\",\n",
    "    base_url='https://dashscope.aliyuncs.com/compatible-mode/v1',\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\")    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c608bd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tongyi_chat = ChatTongyi(\n",
    "    model=\"qwen-max\",\n",
    ")\n",
    "\n",
    "tongyi_chat.invoke(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a9b7bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'aime la programmation.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 37, 'total_tokens': 44, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'qwen-plus', 'system_fingerprint': None, 'id': 'chatcmpl-7e14267c-ef72-98c3-b43d-4d547248a501', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--6f9e27e7-55aa-4884-84c4-f03ff8ee064f-0', usage_metadata={'input_tokens': 37, 'output_tokens': 7, 'total_tokens': 44, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91d31923",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetWeather(BaseModel):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "\n",
    "    location: str = Field(..., description=\"The city and state, e.g. San Francisco, CA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ed132a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lNk5cct9lltWV8wXvFYbdCRU', 'function': {'arguments': '{\"location\":\"San Francisco, CA\"}', 'name': 'GetWeather'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 68, 'total_tokens': 86, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_efad92c60b', 'id': 'chatcmpl-BsQ2gc3OcJukKifQyH5nkNAVxOtCx', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--49de96aa-a497-4dba-8392-aa465abc2077-0', tool_calls=[{'name': 'GetWeather', 'args': {'location': 'San Francisco, CA'}, 'id': 'call_lNk5cct9lltWV8wXvFYbdCRU', 'type': 'tool_call'}], usage_metadata={'input_tokens': 68, 'output_tokens': 18, 'total_tokens': 86, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools = llm.bind_tools([GetWeather])\n",
    "\n",
    "ai_msg = llm_with_tools.invoke(\n",
    "    \"what is the weather like in San Francisco\",\n",
    ")\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80cb72d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(location: str) -> None:\n",
    "    \"\"\"Get weather at a location.\"\"\"\n",
    "    return \"It's sunny.\"\n",
    "\n",
    "\n",
    "class OutputSchema(BaseModel):\n",
    "    \"\"\"Schema for response.\"\"\"\n",
    "\n",
    "    answer: str\n",
    "    justification: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "502f025f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'qwen-plus'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b7da91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm = llm.bind_tools(\n",
    "    [get_weather],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d7d768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call_response = structured_llm.invoke(\"What is the weather in SF?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc1a0e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_weather',\n",
       "  'args': {'location': 'SF'},\n",
       "  'id': 'call_0a7c205605654a7b9b74ad',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call_response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "71d946fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema for structured output\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class SearchQuery(BaseModel):\n",
    "    search_query: str = Field(None, description=\"Query that is optimized web search.\")\n",
    "    justification: str = Field(\n",
    "        None, description=\"Why this query is relevant to the user's request.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Augment the LLM with schema for structured output\n",
    "structured_llm = tongyi_chat.with_structured_output(SearchQuery)\n",
    "\n",
    "# Invoke the augmented LLM\n",
    "# 注意：千问模型在使用结构化输出时需要在消息中提到'json'\n",
    "output = structured_llm.invoke(f\"How does Calcium CT score relate to high cholesterol? Please provide the answer in following JSON format.\\n{SearchQuery.model_json_schema()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e3016dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SearchQuery(search_query='How does Calcium CT score relate to high cholesterol', justification='The user wants to know the relationship between Calcium CT score and high cholesterol. This search query will help in finding relevant information.')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "77863f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'qwen-max'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b76fef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7d7660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "302a0f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'GetWeather',\n",
       "  'args': {'location': 'Los Angeles, CA'},\n",
       "  'id': 'call_17e021f8060d45d8bc33ac',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GetWeather(BaseModel):\n",
    "    '''Get the current weather in a given location'''\n",
    "\n",
    "    location: str = Field(\n",
    "        ..., description=\"The city and state, e.g. San Francisco, CA\"\n",
    "    )\n",
    "\n",
    "\n",
    "class GetPopulation(BaseModel):\n",
    "    '''Get the current population in a given location'''\n",
    "\n",
    "    location: str = Field(\n",
    "        ..., description=\"The city and state, e.g. San Francisco, CA\"\n",
    "    )\n",
    "\n",
    "chat_with_tools = tongyi_chat.bind_tools([GetWeather, GetPopulation])\n",
    "ai_msg = chat_with_tools.invoke(\n",
    "    \"Which city is hotter today and which is bigger: LA or NY?\"\n",
    ")\n",
    "ai_msg.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "923e09d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'name': 'GetWeather', 'arguments': '{\"location\": \"Los Angeles, CA\"}'}, 'index': 0, 'id': 'call_17e021f8060d45d8bc33ac', 'type': 'function'}]}, response_metadata={'model_name': 'qwen-max', 'finish_reason': 'tool_calls', 'request_id': '78d482b2-fc9f-904e-a9ac-763e9f4ea449', 'token_usage': {'input_tokens': 265, 'output_tokens': 22, 'total_tokens': 287, 'prompt_tokens_details': {'cached_tokens': 0}}}, id='run--2cb2d471-faa3-486f-8a3f-057ea8addcbb-0', tool_calls=[{'name': 'GetWeather', 'args': {'location': 'Los Angeles, CA'}, 'id': 'call_17e021f8060d45d8bc33ac', 'type': 'tool_call'}])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8368a43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup=\"Why don't cats play poker in the jungle?\", punchline='Too many cheetahs!', rating=7)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "class Joke(BaseModel):\n",
    "    '''Joke to tell user.'''\n",
    "\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline to the joke\")\n",
    "    rating: Optional[int] = Field(description=\"How funny the joke is, from 1 to 10\")\n",
    "\n",
    "\n",
    "structured_chat = tongyi_chat.with_structured_output(Joke)\n",
    "structured_chat.invoke(\"Tell me a joke about cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683e84d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
